---List of commands to help train Sourccey V3 Beta

###
Sourccey Commands
###

```bash
uv run -m lerobot.auto_calibrate \
    --robot.type=sourccey_v3beta \
    --robot.id=sourccey_v3beta
```

# For hard reset:
```bash
uv run -m lerobot.auto_calibrate \
    --robot.type=sourccey_v3beta\
    --robot.id=sourccey_v3beta \
    --full_reset=True
```

# For Teleoperators

```bash
python -m lerobot.auto_calibrate \
  --teleop.type=bi_sourccey_v3beta_leader \
  --teleop.id=bi_sourccey_v3beta_leader \
  --teleop.left_arm_port="COM4" \
  --teleop.right_arm_port="COM41"
```

```bash
python -m lerobot.calibrate \
    --teleop.type=sourccey_v3beta_leader \
    --teleop.port=COM28 \
    --teleop.id=sourccey_v3beta_leader
```

To teleoperate, SSH into your Raspberry Pi, navigate to the lerobot repo and run this command:

```
uv run -m lerobot.robots.sourccey.sourccey_v3beta.sourccey_v3beta.sourccey_v3beta_host
```

```
nano ~/.cache/huggingface/lerobot/calibration/robots/sourccey_v3beta_follower/sourccey_v3beta_left.json
nano ~/.cache/huggingface/lerobot/calibration/robots/sourccey_v3beta_follower/sourccey_v3beta_right.json
cat ~/.cache/huggingface/lerobot/calibration/robots/sourccey_v3beta_follower/sourccey_v3beta_left.json
cat ~/.cache/huggingface/lerobot/calibration/robots/sourccey_v3beta_follower/sourccey_v3beta_right.json
```

###
Computer Commands
###

Then on your computer run the below source command then the teleoperate command

```
source .venv/bin/activate
```

```
python examples/sourccey/sourccey_v3beta/teleoperate.py
```

```
python examples/sourccey/sourccey_v3beta/record.py
```

```
python examples/sourccey/sourccey_v3beta/replay.py
```

```
python examples/sourccey/sourccey_v3beta/evaluate.py
```

--- ACT Training

```bash
CUDA_VISIBLE_DEVICES=0 python src/lerobot/scripts/train.py \
  --dataset.repo_id=local/sourccey_v3beta-001__ai_test_6 \
  --policy.type=act \
  --output_dir=outputs/train/act__sourccey_v3beta-001__ai_test_6 \
  --job_name=act__sourccey_v3beta-001__ai_test_6 \
  --policy.device=cuda \
  --policy.push_to_hub=false \
  --wandb.enable=false \
  --steps=100000
```

python src/lerobot/scripts/train.py \
  --dataset.repo_id=local/sourccey_v3beta-001__ai_test_4 \
  --policy.type=act \
  --output_dir=outputs/train/act__sourccey_v3beta-001__ai_test_4 \
  --job_name=act__sourccey_v3beta-001__ai_test_4 \
  --policy.device=cuda \
  --save_freq=20000 \
  --policy.push_to_hub=false \
  --wandb.enable=false \
  --steps=100000





```bash
torchrun --nproc_per_node=2 src/lerobot/scripts/train.py \
  --dataset.repo_id=local/sourccey_v3beta-001__ai_test_9  \
  --policy.type=act \
  --output_dir=outputs/train/act_sourccey_v3beta-001__ai_test_9 \
  --job_name=act_sourccey_v3beta-001__ai_test_9  \
  --policy.device=cuda \
  --wandb.enable=false \
  --policy.push_to_hub=false \
  --steps=100000 \
  --save_freq=20000 \
  --batch_size=32 \
  --distributed_training=true \
  --num_gpus=2
```

---- Train on Pretrained SmolVLA model

```bash
CUDA_VISIBLE_DEVICES=0 python lerobot/scripts/train.py \
 --dataset.repo_id=local/sourccey_v2beta_towel_010_a \
 --policy.path=lerobot/smolvla_base \
 --policy.device=cuda \
 --output_dir=outputs/train/smolvla_base_sourccey_v2beta_towel_010_a \
 --job_name=smolvla_base_sourccey_v2beta_towel_010_a \
 --wandb.enable=false \
 --steps=100000 \
 --batch_size=4
```

```bash
torchrun --nproc_per_node=2 lerobot/scripts/train.py \
 --dataset.repo_id=local/sourccey_v2beta_towel_010_a \
 --policy.path=lerobot/smolvla_base \
 --policy.device=cuda \
 --output_dir=outputs/train/smolvla_base_sourccey_v2beta_towel_010_a \
 --job_name=smolvla_base_sourccey_v2beta_towel_010_a \
 --wandb.enable=false \
 --steps=100000 \
 --batch_size=8 \
 --distributed_training=true \
 --num_gpus=2
```

---

--steps=200000 \
 --batch_size=64 \

----- Combine Dataset functions

```bash
python src/lerobot/scripts/combine_dataset.py \
    --repo_ids local/sourccey_v3beta-001__ai_test_4 local/sourccey_v3beta-001__ai_test_4_2 \
    --output_repo_id=local/sourccey_v3beta-001__ai_test_4_combined \
    --push_to_hub=0
```

```bash
python lerobot/scripts/combine_dataset.py \
    --repo_ids local/sourccey_v2beta_towel_010_d local/sourccey_v2beta_towel_010_e \
    --output_repo_id=local/sourccey_v2beta_towel_010_d_e_combined \
    --push_to_hub=0
```

---

## -- SO100

python -m lerobot.find_port
python -m lerobot.find_cameras

python -m lerobot.record \
 --robot.type=so100_follower \
 --robot.port=/dev/ttyUSB0 \
 --robot.id=so100_follower \
 --robot.cameras="{laptop: {type: opencv, index_or_path: /dev/video0, width: 640, height: 480, fps: 30}}" \
 --teleop.type=so100_leader \
 --teleop.port=/dev/ttyUSB1 \
 --teleop.id=so100_leader \
 --dataset.repo_id=local/so100-001-test \
 --dataset.num_episodes=10 \
 --dataset.single_task="Grab the tap and put it in the cup" \
 --dataset.push_to_hub=false \
 --display_data=true

python -m lerobot.record \
 --robot.type=so100_follower \
 --robot.port=COM28 \
 --robot.id=so100_follower \
 --robot.cameras="{laptop: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}}" \
 --teleop.type=so100_leader \
 --teleop.port=COM29 \
 --teleop.id=so100_leader \
 --dataset.repo_id=local/so100-001-test \
 --dataset.num_episodes=10 \
 --dataset.single_task="Grab the tap and put it in the cup" \
 --dataset.push_to_hub=false \
 --display_data=true

torchrun --nproc_per_node=2 lerobot/scripts/train.py \
 --dataset.repo_id=local/so100-001-test \
 --policy.type=act \
 --output_dir=outputs/train/act_so100-001-test \
 --job_name=act_so100-001-test \
 --policy.device=cuda \
 --wandb.enable=false \
 --steps=100000 \
 --save_freq=10000 \
 --batch_size=32 \
 --distributed_training=true \
 --num_gpus=2

python -m lerobot.record \
 --robot.type=so100_follower \
 --robot.port=/dev/ttyUSB0 \
 --robot.id=so100_follower \
 --robot.cameras="{laptop: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}}" \
 --dataset.repo_id=local/eval_so100-001-test \
 --dataset.num_episodes=1 \
 --dataset.single_task="Grab the tap and put it in the cup" \
 --dataset.push_to_hub=false \
 --policy.path=outputs/train/act_so100-001-test/checkpoints/040000/pretrained_model \
 --display_data=true

## -- Server SO100

```
python -m lerobot.record
  --robot.type=so100_double_follower \
  --robot.left_port=/dev/robotLeft \
  --robot.right_port=/dev/ttyUSB2 \
  --robot.id=double_so100_follower \
  --robot.cameras="{ front: {type: opencv, index_or_path: '/dev/video0', width: 640, height: 480, fps: 30}, side: {type: opencv, index_or_path: '/dev/video2', width: 640, height: 480, fps: 30 }" \
  --teleop.type=so100_double_leader \
  --teleop.type=so100_double_leader \
  --teleop.left_port=/dev/ttyUSB1 \
  --teleop.right_port=/dev/ttyUSB0 \
  --teleop.id=so100_double_leader \
  --dataset.repo_id=local/double_so100_towelfold_000 \
  --dataset.num_episodes=1 \
  --dataset.single_task="Dual arm manipulation task" \
  --dataset.push_to_hub=false
```

---

## Sourccey SO100 Test

```
lerobot-teleoperate \
  --robot.type=bi_so100_follower \
  --robot.left_arm_port=/dev/robotLeftArm \
  --robot.right_arm_port=/dev/robotRightArm \
  --robot.id=bi_so100_follower \
  --robot.cameras="{ cameraFrontLeft: {type: opencv, index_or_path: '/dev/video2', width: 640, height: 360, fps: 30}, cameraFrontRight: {type: opencv, index_or_path: '/dev/cameraFrontRight', width: 640, height: 360, fps: 30 }, cameraWristLeft: {type: opencv, index_or_path: '/dev/video4', width: 640, height: 360, fps: 30}, cameraWristRight: {type: opencv, index_or_path: '/dev/video6', width: 640, height: 360, fps: 30} }" \
  --teleop.type=bi_so100_leader \
  --teleop.left_arm_port=/dev/ttyACM3 \
  --teleop.right_arm_port=/dev/ttyACM2 \
  --teleop.id=bi_so100_leader
```

```
nano ~/.cache/huggingface/lerobot/calibration/robots/so100_follower/bi_so100_follower_left.json
nano ~/.cache/huggingface/lerobot/calibration/robots/so100_follower/bi_so100_follower_right.json
cat ~/.cache/huggingface/lerobot/calibration/robots/so100_follower/bi_so100_follower_left.json
cat ~/.cache/huggingface/lerobot/calibration/robots/so100_follower/bi_so100_follower_right.json

nano ~/.cache/huggingface/lerobot/calibration/teleoperators/so100_leader/bi_so100_leader_left.json
nano ~/.cache/huggingface/lerobot/calibration/teleoperators/so100_leader/bi_so100_leader_right.json
cat ~/.cache/huggingface/lerobot/calibration/teleoperators/so100_leader/bi_so100_leader_left.json
cat ~/.cache/huggingface/lerobot/calibration/teleoperators/so100_leader/bi_so100_leader_right.json
```

```
lerobot-record \
  --robot.type=bi_so100_follower \
  --robot.left_arm_port=/dev/robotLeftArm \
  --robot.right_arm_port=/dev/robotRightArm \
  --robot.id=bi_so100_follower \
  --robot.cameras="{ cameraFrontLeft: {type: opencv, index_or_path: '/dev/video2', width: 640, height: 360, fps: 30}, cameraFrontRight: {type: opencv, index_or_path: '/dev/cameraFrontRight', width: 640, height: 360, fps: 30 }, cameraWristLeft: {type: opencv, index_or_path: '/dev/video4', width: 640, height: 360, fps: 30}, cameraWristRight: {type: opencv, index_or_path: '/dev/video6', width: 640, height: 360, fps: 30} }" \
  --teleop.type=bi_so100_leader \
  --teleop.left_arm_port=/dev/ttyACM3 \
  --teleop.right_arm_port=/dev/ttyACM2 \
  --teleop.id=bi_so100_leader \
  --dataset.repo_id=local/ai_test_2 \
  --dataset.num_episodes=10 \
  --dataset.episode_time_s=25 \
  --dataset.reset_time_s=5 \
  --dataset.single_task="Grab the tape and put it in the cup" \
  --dataset.push_to_hub=false
```

```
cd ~/Desktop/Projects/lerobot-vulcan-nightly
cd ~/.cache/huggingface/lerobot/local
rm -r ~/.cache/huggingface/lerobot/local/ai_test_2
```





sourccey_v3beta-001__ai_test_4_combined



python src/lerobot/scripts/train.py \
  --dataset.repo_id=local/sourccey_v3beta-001__ai_test_4_combined \
  --policy.type=act \
  --output_dir=outputs/train/act__sourccey_v3beta-001__ai_test_4_combined \
  --job_name=act__sourccey_v3beta-001__ai_test_4_combined \
  --policy.device=cuda \
  --save_freq=20000 \
  --policy.push_to_hub=false \
  --wandb.enable=false \
  --steps=20000
